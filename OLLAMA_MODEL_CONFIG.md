# Ollama 모델 설정 가이드

## 업무별 모델 분장

각 업무에 맞는 최적화된 경량 모델을 사용하여 서버 부하를 최소화합니다.

### 모델 구성

1. **스캐너 모델** (`OLLAMA_SCANNER_MODEL`)
   - 용도: 코인 정보 수집 (거래량, 가격, 기술적 지표)
   - 기본값: `qwen2.5:0.5b`
   - 특징: 가장 경량, 빠른 스캔 속도
   - 사용 위치: `CoinScanner.scan_single_market()`

2. **1차 분석 모델** (`OLLAMA_FIRST_ROUND_MODEL`)
   - 용도: 거래량 상위 30개 코인 스캔
   - 기본값: `qwen2.5:0.5b`
   - 특징: 경량, 빠른 처리
   - 사용 위치: (현재는 스캐너 모델과 동일)

3. **2차 분석 모델** (`OLLAMA_SECOND_ROUND_MODEL`)
   - 용도: 상위 10개 코인 선정 (점수 계산)
   - 기본값: `qwen2.5:1b`
   - 특징: 중간 경량, 점수 계산 정확도
   - 사용 위치: `TradingDecisionMaker.select_top_candidates()` (향후 확장)

4. **최종 결정 모델** (`OLLAMA_DECISION_MODEL`)
   - 용도: 상위 5개 중 최종 매매 결정
   - 기본값: `qwen2.5:1.5b`
   - 특징: 약간 더 큰 모델, 판단력 필요
   - 사용 위치: `TradingDecisionMaker.make_decision()`

## 환경 변수 설정

```bash
# 스캐너 모델 (정보 수집용)
export OLLAMA_SCANNER_MODEL="qwen2.5:0.5b"

# 1차 분석 모델 (거래량 상위 30개)
export OLLAMA_FIRST_ROUND_MODEL="qwen2.5:0.5b"

# 2차 분석 모델 (상위 10개 선정)
export OLLAMA_SECOND_ROUND_MODEL="qwen2.5:1b"

# 최종 결정 모델 (상위 5개 중 선택)
export OLLAMA_DECISION_MODEL="qwen2.5:1.5b"

# Ollama 서버 URL
export OLLAMA_BASE_URL="http://127.0.0.1:11434"
```

## 모델 설치

각 모델을 Ollama에 설치해야 합니다:

```bash
# 스캐너 및 1차 분석 모델
ollama pull qwen2.5:0.5b

# 2차 분석 모델
ollama pull qwen2.5:1b

# 최종 결정 모델
ollama pull qwen2.5:1.5b
```

## 모델 확인

설치된 모델 확인:

```bash
ollama list
```

## 권장 모델 조합

### 경량 구성 (서버 부하 최소화)
- 스캐너: `qwen2.5:0.5b`
- 1차 분석: `qwen2.5:0.5b`
- 2차 분석: `qwen2.5:1b`
- 최종 결정: `qwen2.5:1.5b`

### 균형 구성 (성능과 부하 균형)
- 스캐너: `qwen2.5:1b`
- 1차 분석: `qwen2.5:1b`
- 2차 분석: `qwen2.5:1.5b`
- 최종 결정: `qwen2.5:3b`

### 고성능 구성 (정확도 우선)
- 스캐너: `qwen2.5:1.5b`
- 1차 분석: `qwen2.5:1.5b`
- 2차 분석: `qwen2.5:3b`
- 최종 결정: `qwen2.5:7b`

## 모델별 특징

### qwen2.5:0.5b
- 파라미터: 0.5B
- 메모리: ~300MB
- 속도: 매우 빠름
- 정확도: 기본 수준
- 용도: 빠른 스캔, 정보 수집

### qwen2.5:1b
- 파라미터: 1B
- 메모리: ~600MB
- 속도: 빠름
- 정확도: 양호
- 용도: 중간 분석, 점수 계산

### qwen2.5:1.5b
- 파라미터: 1.5B
- 메모리: ~900MB
- 속도: 보통
- 정확도: 좋음
- 용도: 최종 결정, 판단

### qwen2.5:3b
- 파라미터: 3B
- 메모리: ~2GB
- 속도: 느림
- 정확도: 매우 좋음
- 용도: 복잡한 분석

### qwen2.5:7b
- 파라미터: 7B
- 메모리: ~4GB
- 속도: 매우 느림
- 정확도: 최고
- 용도: 고급 분석 (서버 부하 고려 필요)

## 주의사항

1. **메모리 사용량**: 여러 모델을 동시에 사용하면 메모리 사용량이 증가합니다.
2. **모델 로딩 시간**: 첫 사용 시 모델 로딩 시간이 필요합니다.
3. **서버 부하**: 모델 크기가 클수록 CPU/GPU 부하가 증가합니다.
4. **호환성**: 모든 모델이 Ollama 0.1.0+ 에서 지원됩니다.

## 문제 해결

### 모델을 찾을 수 없음
```bash
# 모델 재설치
ollama pull qwen2.5:0.5b
```

### 메모리 부족
- 더 작은 모델 사용
- 모델을 순차적으로 사용 (동시 사용 최소화)

### 응답 시간 지연
- 더 작은 모델 사용
- 타임아웃 증가 (`timeout` 파라미터 조정)

