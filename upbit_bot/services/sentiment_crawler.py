"""ê°ì • ì§€í‘œ í¬ë¡¤ëŸ¬ (AI ì—†ì´ í‚¤ì›Œë“œ/ì´ëª¨ì§€ ê¸°ë°˜ ë¶„ì„)."""

from __future__ import annotations

import logging
import re
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, UTC
from typing import Any

import requests

LOGGER = logging.getLogger(__name__)

# ê°ì • ë‹¨ì–´ ì‚¬ì „ (AI ì—†ì´ ì‚¬ìš©)
POSITIVE_WORDS = {
    "ìƒìŠ¹", "ê¸‰ë“±", "í­ë“±", "ì‹ ê³ ê°€", "ê³¨ë“ í¬ë¡œìŠ¤", "ëŒíŒŒ", "ê°•ì„¸", "í˜¸ì¬",
    "ìƒì¥", "ìƒìŠ¹ì„¸", "ë§¤ìˆ˜", "ë¡±", "ğŸš€", "ğŸ“ˆ", "ğŸ’", "ğŸ”¥", "â­", "ğŸ’ª",
    "good", "bullish", "pump", "moon", "lambo", "hodl", "buy", "long",
    "rally", "breakout", "support", "resistance", "bull", "green"
}

NEGATIVE_WORDS = {
    "í•˜ë½", "ê¸‰ë½", "í­ë½", "ì‹ ì €ê°€", "ë°ë“œí¬ë¡œìŠ¤", "ì¹¨ì²´", "ì•½ì„¸", "ì•…ì¬",
    "ìƒì¥íì§€", "í•˜ë½ì„¸", "ë§¤ë„", "ìˆ", "ğŸ˜±", "ğŸ“‰", "ğŸ’€", "âš ï¸", "ğŸš¨", "ğŸ’”",
    "bad", "bearish", "dump", "crash", "rug", "scam", "sell", "short",
    "fall", "breakdown", "rejection", "bear", "red"
}


class SentimentCrawler:
    """ê°ì • ì§€í‘œ í¬ë¡¤ëŸ¬ (AI ì—†ì´ í‚¤ì›Œë“œ/ì´ëª¨ì§€ ê¸°ë°˜ ë¶„ì„)."""

    def __init__(self, timeout: int = 5, cache_ttl: int = 1800):
        """
        Args:
            timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ, ê¸°ë³¸ê°’: 5ì´ˆ, ë¹ ë¥¸ ì‹¤íŒ¨ ê°ì§€)
            cache_ttl: ìºì‹œ ìœ ì§€ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 1800ì´ˆ = 30ë¶„)
        """
        self.timeout = timeout
        self.cache_ttl = cache_ttl
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        })
        
        # ìºì‹œ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self._cache: dict[str, tuple[dict[str, Any], datetime]] = {}
        self._cache_lock = threading.Lock()

    def crawl_reddit_sentiment(
        self, coin_symbol: str, limit: int = 30, subreddit: str | None = None, use_cache: bool = True
    ) -> dict[str, Any]:
        """
        Redditì—ì„œ ì½”ì¸ ê°ì • ì§€í‘œ í¬ë¡¤ë§.
        
        Args:
            coin_symbol: ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: "BTC", "ETH")
            limit: ìµœëŒ€ ê²Œì‹œë¬¼ ìˆ˜ (ê¸°ë³¸ê°’: 30)
            subreddit: ì„œë¸Œë ˆë”§ ì´ë¦„ (Noneì´ë©´ coin_symbol ì‚¬ìš©)
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
        Returns:
            ê°ì • ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        """
        # ìºì‹œ í™•ì¸
        if use_cache:
            with self._cache_lock:
                if coin_symbol in self._cache:
                    cached_result, cached_time = self._cache[coin_symbol]
                    age = (datetime.now(UTC) - cached_time).total_seconds()
                    if age < self.cache_ttl:
                        LOGGER.debug(f"Reddit ìºì‹œ ì‚¬ìš© ({coin_symbol}): {age:.0f}ì´ˆ ì „ ê²°ê³¼")
                        return cached_result
        
        subreddit_name = subreddit or coin_symbol
        try:
            # Reddit JSON API ì‚¬ìš© (ê³µê°œ, API í‚¤ ë¶ˆí•„ìš”)
            url = f"https://www.reddit.com/r/{subreddit_name}/hot.json"
            params = {"limit": min(limit, 100)}
            
            response = self.session.get(url, params=params, timeout=self.timeout)
            
            if response.status_code == 404:
                # ì„œë¸Œë ˆë”§ì´ ì—†ìœ¼ë©´ ê²€ìƒ‰ ì‹œë„
                LOGGER.debug(f"ì„œë¸Œë ˆë”§ r/{subreddit_name} ì—†ìŒ, ê²€ìƒ‰ ì‹œë„")
                return self._crawl_reddit_search(coin_symbol, limit)
            
            if response.status_code != 200:
                LOGGER.warning(f"Reddit í¬ë¡¤ë§ ì‹¤íŒ¨: HTTP {response.status_code}")
                return {"sentiment": 0.5, "source": "reddit", "error": f"HTTP {response.status_code}"}
            
            data = response.json()
            posts = data.get("data", {}).get("children", [])
            
            if not posts:
                LOGGER.debug(f"Reddit ê²Œì‹œë¬¼ ì—†ìŒ: r/{subreddit_name}")
                return {"sentiment": 0.5, "source": "reddit", "post_count": 0}
            
            # ê°ì • ë¶„ì„
            total_sentiment = 0.0
            post_count = 0
            
            for post_data in posts:
                post = post_data.get("data", {})
                title = post.get("title", "").lower()
                selftext = post.get("selftext", "").lower()
                text = f"{title} {selftext}"
                
                # í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì ìˆ˜ ê³„ì‚°
                sentiment = self._calculate_keyword_sentiment(text)
                
                # ì—…ë³´íŠ¸ ë¹„ìœ¨ ë°˜ì˜
                ups = post.get("ups", 0)
                downs = max(post.get("downs", 0), 0)  # ë‹¤ìš´ë³´íŠ¸ëŠ” í•­ìƒ 0 (Reddit API)
                total_votes = ups + downs
                if total_votes > 0:
                    upvote_ratio = ups / total_votes
                    # ì—…ë³´íŠ¸ ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ ê°ì • ì ìˆ˜ ìƒí–¥
                    sentiment = (sentiment * 0.7) + (upvote_ratio * 0.3)
                
                # ì½”ë©˜íŠ¸ ë¹„ìœ¨ ë°˜ì˜ (ëŒ“ê¸€ì´ ë§ìœ¼ë©´ ê´€ì‹¬ë„ ë†’ìŒ)
                num_comments = post.get("num_comments", 0)
                if num_comments > 0:
                    # ëŒ“ê¸€ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì•½ê°„ ìƒí–¥ (ìµœëŒ€ 0.1 í¬ì¸íŠ¸)
                    comment_bonus = min(num_comments / 100.0, 0.1)
                    sentiment = min(sentiment + comment_bonus, 1.0)
                
                total_sentiment += sentiment
                post_count += 1
            
            avg_sentiment = total_sentiment / post_count if post_count > 0 else 0.5
            
            LOGGER.debug(
                f"Reddit ê°ì • ë¶„ì„ ({coin_symbol}): {avg_sentiment:.2f} "
                f"(ê²Œì‹œë¬¼ {post_count}ê°œ)"
            )
            
            result = {
                "sentiment": avg_sentiment,  # 0.0 (ë¶€ì •) ~ 1.0 (ê¸ì •)
                "source": "reddit",
                "post_count": post_count,
                "subreddit": subreddit_name,
                "timestamp": datetime.now(UTC).isoformat(),
            }
            
            # ìºì‹œ ì €ì¥
            if use_cache and "error" not in result:
                with self._cache_lock:
                    self._cache[coin_symbol] = (result, datetime.now(UTC))
            
            return result
            
        except requests.exceptions.Timeout:
            LOGGER.debug(f"Reddit í¬ë¡¤ë§ íƒ€ì„ì•„ì›ƒ ({coin_symbol})")
            # íƒ€ì„ì•„ì›ƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ìºì‹œ ì €ì¥ ì•ˆí•¨)
            return {"sentiment": 0.5, "source": "reddit", "error": "timeout"}
        except Exception as e:
            LOGGER.debug(f"Reddit í¬ë¡¤ë§ ì˜¤ë¥˜ ({coin_symbol}): {e}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (ìºì‹œ ì €ì¥ ì•ˆí•¨)
            return {"sentiment": 0.5, "source": "reddit", "error": str(e)[:50]}

    def _crawl_reddit_search(self, coin_symbol: str, limit: int = 30) -> dict[str, Any]:
        """
        Reddit ê²€ìƒ‰ìœ¼ë¡œ ì½”ì¸ ê°ì • ì§€í‘œ í¬ë¡¤ë§.
        
        Args:
            coin_symbol: ì½”ì¸ ì‹¬ë³¼
            limit: ìµœëŒ€ ê²Œì‹œë¬¼ ìˆ˜
        
        Returns:
            ê°ì • ì§€í‘œ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # Reddit ê²€ìƒ‰ API ì‚¬ìš©
            url = "https://www.reddit.com/search.json"
            params = {
                "q": coin_symbol,
                "sort": "hot",
                "limit": min(limit, 25),  # ê²€ìƒ‰ì€ ìµœëŒ€ 25ê°œ
                "t": "day",  # ìµœê·¼ 1ì¼
            }
            
            response = self.session.get(url, params=params, timeout=self.timeout)
            
            if response.status_code != 200:
                return {"sentiment": 0.5, "source": "reddit_search", "error": f"HTTP {response.status_code}"}
            
            data = response.json()
            posts = data.get("data", {}).get("children", [])
            
            if not posts:
                return {"sentiment": 0.5, "source": "reddit_search", "post_count": 0}
            
            # ê°ì • ë¶„ì„ (ì„œë¸Œë ˆë”§ê³¼ ë™ì¼í•œ ë°©ì‹)
            total_sentiment = 0.0
            post_count = 0
            
            for post_data in posts:
                post = post_data.get("data", {})
                title = post.get("title", "").lower()
                selftext = post.get("selftext", "").lower()
                text = f"{title} {selftext}"
                
                # ì½”ì¸ ì‹¬ë³¼ì´ í¬í•¨ëœ ê²½ìš°ë§Œ ë¶„ì„
                if coin_symbol.lower() not in text:
                    continue
                
                sentiment = self._calculate_keyword_sentiment(text)
                
                ups = post.get("ups", 0)
                total_votes = ups
                if total_votes > 0:
                    upvote_ratio = ups / (total_votes + 10)  # ë‹¤ìš´ë³´íŠ¸ ì¶”ì •
                    sentiment = (sentiment * 0.7) + (upvote_ratio * 0.3)
                
                total_sentiment += sentiment
                post_count += 1
            
            avg_sentiment = total_sentiment / post_count if post_count > 0 else 0.5
            
            return {
                "sentiment": avg_sentiment,
                "source": "reddit_search",
                "post_count": post_count,
                "timestamp": datetime.now(UTC).isoformat(),
            }
            
        except Exception as e:
            LOGGER.warning(f"Reddit ê²€ìƒ‰ í¬ë¡¤ë§ ì˜¤ë¥˜ ({coin_symbol}): {e}")
            return {"sentiment": 0.5, "source": "reddit_search", "error": str(e)[:50]}

    def _calculate_keyword_sentiment(self, text: str) -> float:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0).
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
        Returns:
            ê°ì • ì ìˆ˜ (0.0: ë¶€ì •, 1.0: ê¸ì •, 0.5: ì¤‘ë¦½)
        """
        text_lower = text.lower()
        
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚°
        positive_count = sum(1 for word in POSITIVE_WORDS if word.lower() in text_lower)
        negative_count = sum(1 for word in NEGATIVE_WORDS if word.lower() in text_lower)
        
        # ì´ëª¨ì§€ ë¶„ì„
        emoji_positive = len(re.findall(r'[ğŸš€ğŸ“ˆğŸ’ğŸ”¥â­ğŸ’ªğŸ’šğŸŸ¢]', text))
        emoji_negative = len(re.findall(r'[ğŸ˜±ğŸ“‰ğŸ’€âš ï¸ğŸš¨ğŸ’”ğŸ”´]', text))
        
        positive_total = positive_count + (emoji_positive * 2)  # ì´ëª¨ì§€ëŠ” ê°€ì¤‘ì¹˜ 2ë°°
        negative_total = negative_count + (emoji_negative * 2)
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        total = positive_total + negative_total
        if total == 0:
            return 0.5  # ì¤‘ë¦½
        
        sentiment = positive_total / total
        
        # 0.3 ~ 0.7 ë²”ìœ„ë¡œ ì •ê·œí™” (ê·¹ë‹¨ì ì¸ ê°’ ë°©ì§€)
        normalized_sentiment = 0.3 + (sentiment * 0.4)
        
        return normalized_sentiment

    def crawl_multiple_coins(
        self,
        coin_symbols: list[str],
        max_workers: int = 3,  # Reddit rate limit ê³ ë ¤ (3ê°œë¡œ ì œí•œ)
        limit_per_coin: int = 20,  # ê²Œì‹œë¬¼ ìˆ˜ ê°ì†Œ (20ê°œë¡œ ì œí•œ)
        top_n_only: int | None = None,  # ìƒìœ„ Nê°œë§Œ í¬ë¡¤ë§ (Noneì´ë©´ ì „ì²´)
    ) -> dict[str, dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì½”ì¸ì˜ Reddit ê°ì • ì§€í‘œë¥¼ ë³‘ë ¬ë¡œ í¬ë¡¤ë§.
        
        Args:
            coin_symbols: ì½”ì¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
            max_workers: ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’: 3, Reddit rate limit ê³ ë ¤)
            limit_per_coin: ì½”ì¸ë‹¹ ìµœëŒ€ ê²Œì‹œë¬¼ ìˆ˜ (ê¸°ë³¸ê°’: 20, ì†ë„ í–¥ìƒ)
            top_n_only: ìƒìœ„ Nê°œë§Œ í¬ë¡¤ë§ (Noneì´ë©´ ì „ì²´, ì˜ˆ: 10)
        
        Returns:
            {coin_symbol: sentiment_data} ë”•ì…”ë„ˆë¦¬
        """
        # ìƒìœ„ Nê°œë§Œ í¬ë¡¤ë§ (ê²€í†  ì‹œê°„ ë‹¨ì¶•)
        if top_n_only and top_n_only < len(coin_symbols):
            coin_symbols = coin_symbols[:top_n_only]
            LOGGER.info(f"Reddit í¬ë¡¤ë§: ìƒìœ„ {top_n_only}ê°œ ì½”ì¸ë§Œ í¬ë¡¤ë§ (ê²€í†  ì‹œê°„ ë‹¨ì¶•)")
        
        results: dict[str, dict[str, Any]] = {}
        results_lock = threading.Lock()
        
        def crawl_one(coin_symbol: str) -> tuple[str, dict[str, Any]]:
            """ë‹¨ì¼ ì½”ì¸ í¬ë¡¤ë§ ë˜í¼."""
            try:
                # ìš”ì²­ ê°„ ì§§ì€ ë”œë ˆì´ (rate limit ë°©ì§€)
                time.sleep(0.5)
                result = self.crawl_reddit_sentiment(
                    coin_symbol, 
                    limit=limit_per_coin,
                    use_cache=True  # ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¥¸ ë°˜í™˜
                )
                return coin_symbol, result
            except Exception as e:
                LOGGER.debug(f"Reddit í¬ë¡¤ë§ ì‹¤íŒ¨ ({coin_symbol}): {e}")
                return coin_symbol, {"sentiment": 0.5, "source": "reddit", "error": str(e)[:50]}
        
        LOGGER.info(
            f"Reddit ê°ì • ì§€í‘œ í¬ë¡¤ë§ ì‹œì‘: {len(coin_symbols)}ê°œ ì½”ì¸ "
            f"(ë³‘ë ¬: {max_workers}ê°œ, íƒ€ì„ì•„ì›ƒ: {self.timeout}ì´ˆ)"
        )
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ (ë¹ ë¥¸ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì „ì²´ ê²€í†  ì‹œê°„ ë‹¨ì¶•)
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(crawl_one, coin_symbol): coin_symbol
                for coin_symbol in coin_symbols
            }
            
            completed = 0
            failed = 0
            try:
                # ì „ì²´ íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (30ê°œ * 5ì´ˆ / 3 workers â‰ˆ 50ì´ˆ, ìµœëŒ€ 60ì´ˆë¡œ ì„¤ì •)
                total_timeout = min(60, len(coin_symbols) * self.timeout / max_workers + 10)
                
                for future in as_completed(futures, timeout=total_timeout):
                    completed += 1
                    try:
                        coin_symbol, result = future.result(timeout=1)  # ê°œë³„ ê²°ê³¼ íƒ€ì„ì•„ì›ƒ 1ì´ˆ
                        with results_lock:
                            results[coin_symbol] = result
                        
                        if completed % 10 == 0 or completed == len(coin_symbols):
                            LOGGER.info(
                                f"Reddit í¬ë¡¤ë§ ì§„í–‰: {completed}/{len(coin_symbols)} ì™„ë£Œ "
                                f"({len(results)}ê°œ ì„±ê³µ, {failed}ê°œ ì‹¤íŒ¨)"
                            )
                    except Exception as e:
                        coin_symbol = futures.get(future, "unknown")
                        failed += 1
                        LOGGER.debug(f"Reddit í¬ë¡¤ë§ ì²˜ë¦¬ ì˜¤ë¥˜ ({coin_symbol}): {e}")
                        # ê¸°ë³¸ê°’ ì €ì¥
                        with results_lock:
                            results[coin_symbol] = {"sentiment": 0.5, "source": "reddit", "error": "timeout"}
            except Exception as e:
                LOGGER.warning(f"Reddit í¬ë¡¤ë§ íƒ€ì„ì•„ì›ƒ: {e}, ì™„ë£Œëœ {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
                # íƒ€ì„ì•„ì›ƒëœ ì½”ì¸ë“¤ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                for coin_symbol in coin_symbols:
                    if coin_symbol not in results:
                        results[coin_symbol] = {"sentiment": 0.5, "source": "reddit", "error": "timeout"}
        
        LOGGER.info(
            f"Reddit ê°ì • ì§€í‘œ í¬ë¡¤ë§ ì™„ë£Œ: {len(results)}ê°œ ì½”ì¸ ë¶„ì„ë¨ "
            f"(ì„±ê³µë¥ : {sum(1 for r in results.values() if 'error' not in r) / len(results) * 100:.1f}%)"
        )
        
        return results

