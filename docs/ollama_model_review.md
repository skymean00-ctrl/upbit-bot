# Ollama 모델 검토 및 설치 가이드

## 현재 사용 중인 모델

**모델**: `qwen2.5-coder:7b`  
**용도**: 코인 거래 분석  
**서버**: `http://100.98.189.30:11434`

## 코인 거래 전용 모델 검토

현재 `qwen2.5-coder:7b`는 코딩에 최적화된 모델입니다. 코인 거래에 더 적합한 모델을 검토하겠습니다.

### 추천 모델 후보

#### 1. **Llama 3.1 (8B 또는 70B)**
- **장점**: 일반적인 추론 능력이 뛰어나고 금융 데이터 분석에 적합
- **설치**: `ollama pull llama3.1:8b` 또는 `ollama pull llama3.1:70b`
- **추천 이유**: 범용 LLM으로 금융 데이터 분석 프롬프트에 잘 응답

#### 2. **DeepSeek-R1 (7B)**
- **장점**: 추론 능력이 뛰어나고 수학적 계산에 강함 (가격 분석에 유리)
- **설치**: `ollama pull deepseek-r1:7b`
- **추천 이유**: 금융 데이터의 수치적 분석에 적합

#### 3. **Mistral 7B Instruct**
- **장점**: 지시 따르기 능력이 뛰어나고 프롬프트 엔지니어링에 적합
- **설치**: `ollama pull mistral:7b-instruct`
- **추천 이유**: 거래 전략 프롬프트를 정확히 이해하고 실행

#### 4. **Qwen2.5 (일반 버전, Coder 아님)**
- **장점**: 범용 모델로 다양한 작업에 적합
- **설치**: `ollama pull qwen2.5:7b` 또는 `qwen2.5:14b`
- **추천 이유**: 현재 사용 중인 Qwen 계열이지만 코딩이 아닌 범용 버전

### 코인 거래에 특화된 Fine-tuned 모델

현재 공개된 코인 거래 전용 Fine-tuned 모델은 제한적입니다. 다음과 같은 방법으로 최적화할 수 있습니다:

1. **Modelfile을 이용한 커스텀 모델 생성**
   - 기존 모델에 코인 거래 관련 프롬프트 템플릿 추가
   - 거래 전략, 기술적 지표 해석에 특화된 시스템 프롬프트 설정

2. **프롬프트 엔지니어링 최적화**
   - 현재 모델의 프롬프트를 더 구체적으로 개선
   - 코인 거래 전문 용어와 패턴을 명시적으로 포함

## 권장 사항

### 단기 (즉시 적용 가능)
1. **Llama 3.1 8B 설치 및 테스트**
   ```bash
   ollama pull llama3.1:8b
   ```
   - 현재 `qwen2.5-coder:7b`와 비슷한 크기
   - 일반 추론 능력이 뛰어나 코인 거래 분석에 더 적합할 수 있음

2. **DeepSeek-R1 7B 설치 및 테스트**
   ```bash
   ollama pull deepseek-r1:7b
   ```
   - 수치 분석에 강함
   - 가격 변동 패턴 분석에 유리

### 중기 (성능 비교 후 결정)
1. 여러 모델을 동시에 테스트하여 성능 비교
2. 거래 신호 정확도, 응답 속도, 리소스 사용량 비교
3. 가장 성능이 좋은 모델로 전환

### 장기 (선택사항)
1. **코인 거래 전용 Fine-tuned 모델 생성**
   - 거래 데이터로 Fine-tuning
   - Modelfile을 이용한 커스텀 모델 생성

## 모델 변경 방법

코드에서 모델을 변경하려면 `upbit_bot/strategies/ai_market_analyzer.py` 파일의 `OLLAMA_MODEL` 변수를 수정:

```python
# 기본 모델 (현재)
OLLAMA_MODEL = "qwen2.5-coder:7b"

# Llama 3.1로 변경 예시
OLLAMA_MODEL = "llama3.1:8b"

# DeepSeek-R1로 변경 예시
OLLAMA_MODEL = "deepseek-r1:7b"
```

## 설치 스크립트

```bash
#!/bin/bash
# Ollama 코인 거래 최적화 모델 설치 스크립트

echo "코인 거래 최적화 Ollama 모델 설치 중..."

# Llama 3.1 8B (추천)
echo "1. Llama 3.1 8B 설치 중..."
ollama pull llama3.1:8b

# DeepSeek-R1 7B
echo "2. DeepSeek-R1 7B 설치 중..."
ollama pull deepseek-r1:7b

# Qwen2.5 범용 버전
echo "3. Qwen2.5 7B (범용) 설치 중..."
ollama pull qwen2.5:7b

echo "설치 완료! 다음 모델을 사용할 수 있습니다:"
echo "  - llama3.1:8b"
echo "  - deepseek-r1:7b"
echo "  - qwen2.5:7b"
```

## 모델 선택 가이드

| 모델 | 크기 | 추론 속도 | 정확도 | 코인 거래 적합도 |
|------|------|-----------|--------|------------------|
| qwen2.5-coder:7b (현재) | 7B | 빠름 | 중간 | 중간 (코딩 특화) |
| llama3.1:8b | 8B | 빠름 | 높음 | 높음 |
| deepseek-r1:7b | 7B | 중간 | 높음 | 높음 (수치 분석 강점) |
| mistral:7b-instruct | 7B | 빠름 | 높음 | 중상 |
| qwen2.5:7b | 7B | 빠름 | 중상 | 중상 |

## 다음 단계

1. **모델 설치**: 위의 설치 스크립트 실행
2. **성능 테스트**: 각 모델로 실제 거래 분석 수행 및 결과 비교
3. **최적 모델 선택**: 테스트 결과를 바탕으로 최적 모델 결정
4. **코드 업데이트**: 선택한 모델로 `OLLAMA_MODEL` 변경
5. **모니터링**: 거래 성과 모니터링 및 필요시 재조정

